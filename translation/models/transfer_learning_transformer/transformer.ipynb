{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:26.837990Z",
     "start_time": "2024-10-14T18:50:24.267543Z"
    }
   },
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from translation.translation_dataloader import TranslationDataset\n",
    "from translation.models.transfer_learning_transformer.gec_dataloader import GecDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from translation.models.baseline_transformer.model import Seq2SeqTransformer\n",
    "import nltk\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:26.854096Z",
     "start_time": "2024-10-14T18:50:26.837990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_text_transform():\n",
    "    def sequential_transforms(*transforms):\n",
    "        def func(txt_input):\n",
    "            for transform in transforms:\n",
    "                txt_input = transform(txt_input)\n",
    "            return txt_input\n",
    "        return func\n",
    "\n",
    "    def tensor_transform(token_ids):\n",
    "        return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                          torch.tensor(token_ids),\n",
    "                          torch.tensor([EOS_IDX])))\n",
    "\n",
    "    text_transform = sequential_transforms(token_transform,\n",
    "                                               vocab_transform,\n",
    "                                               tensor_transform)\n",
    "    return text_transform\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(build_text_transform()(src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(build_text_transform()(tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = build_text_transform()(src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform.lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def bleu_evaluation(transformer, test_iter):\n",
    "    score = 0\n",
    "    for sample, target in test_iter:\n",
    "        prediction = translate(transformer, sample).split()\n",
    "        print(sample, \"-\", \" \".join(prediction))\n",
    "        target = target.split()\n",
    "        if len(sample) < 3 or len(target) < 3:\n",
    "            BLEUscore = nltk.translate.bleu_score.sentence_bleu([target], prediction, weights=[0.5, 0.5, 0, 0])\n",
    "        else:\n",
    "            BLEUscore = nltk.translate.bleu_score.sentence_bleu([target], prediction)\n",
    "        score += BLEUscore\n",
    "    return score / len(test_iter)\n"
   ],
   "id": "b02233fa9a3a1cf8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:26.933992Z",
     "start_time": "2024-10-14T18:50:26.854096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = TranslationDataset((\"E:/Python/Projects/PSL-Translator/translation/data_collection/data.txt\",))\n",
    "data_gec = GecDataset(\"gec_dataset.jsonl\")"
   ],
   "id": "a951c4de590615e5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:28.319215Z",
     "start_time": "2024-10-14T18:50:26.933992Z"
    }
   },
   "cell_type": "code",
   "source": "token_transform = get_tokenizer('spacy', language='pl_core_news_sm')",
   "id": "d274144e540a8e9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:28.334982Z",
     "start_time": "2024-10-14T18:50:28.320794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def yield_tokens(data_iter: Iterable) -> List[str]:\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform(data_sample[0])\n",
    "        yield token_transform(data_sample[1])"
   ],
   "id": "eb220d29adeb7134",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:28.350947Z",
     "start_time": "2024-10-14T18:50:28.335997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
   ],
   "id": "dd7cb43e1423c89b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:28.444825Z",
     "start_time": "2024-10-14T18:50:28.351453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_transform = build_vocab_from_iterator(yield_tokens(data),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "vocab_transform.set_default_index(UNK_IDX)"
   ],
   "id": "15de65e4de1dd789",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:29.876080Z",
     "start_time": "2024-10-14T18:50:28.445892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "VOCAB_SIZE = len(vocab_transform)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "train_iter, val_iter, test_iter = torch.utils.data.random_split(data, [0.9, 0.05, 0.05])\n",
    "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "gec_train_iter, gec_val_iter = torch.utils.data.random_split(data_gec, [0.97, 0.03])\n",
    "gec_train_dataloader = DataLoader(gec_train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "gec_val_dataloader = DataLoader(gec_val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, VOCAB_SIZE, VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ],
   "id": "5f2c3b219bab4f9c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Projects\\pythonProject4\\venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:50:29.885728Z",
     "start_time": "2024-10-14T18:50:29.877087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def train_epoch(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    for src, tgt in dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    \n",
    "\n",
    "    for src, tgt in dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))"
   ],
   "id": "30f99af8ea289a40",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:10:27.288238Z",
     "start_time": "2024-10-14T18:50:29.887268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS_GEC = 10\n",
    "\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS_GEC+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer, gec_train_dataloader)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer, gec_val_dataloader)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    \n",
    "torch.save(transformer.state_dict(), \"gec_transformer.pth\")"
   ],
   "id": "6964740c158ff171",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Projects\\pythonProject4\\venv\\lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "E:\\Python\\Projects\\pythonProject4\\venv\\lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 2.385, Val loss: 1.834, Epoch time = 109.996s\n",
      "Epoch: 2, Train loss: 1.664, Val loss: 1.549, Epoch time = 114.957s\n",
      "Epoch: 3, Train loss: 1.395, Val loss: 1.246, Epoch time = 116.257s\n",
      "Epoch: 4, Train loss: 1.150, Val loss: 1.021, Epoch time = 117.697s\n",
      "Epoch: 5, Train loss: 0.942, Val loss: 0.806, Epoch time = 117.929s\n",
      "Epoch: 6, Train loss: 0.790, Val loss: 0.681, Epoch time = 118.334s\n",
      "Epoch: 7, Train loss: 0.671, Val loss: 0.555, Epoch time = 121.415s\n",
      "Epoch: 8, Train loss: 0.586, Val loss: 0.491, Epoch time = 123.742s\n",
      "Epoch: 9, Train loss: 0.520, Val loss: 0.448, Epoch time = 124.228s\n",
      "Epoch: 10, Train loss: 0.465, Val loss: 0.437, Epoch time = 123.470s\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:32:33.847086Z",
     "start_time": "2024-10-14T19:32:16.715295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_EPOCHS_TRANSLATION = 20\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, VOCAB_SIZE, VOCAB_SIZE, FFN_HID_DIM)\n",
    "transformer.to(DEVICE)\n",
    "transformer.load_state_dict(torch.load('gec_transformer.pth'))\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer.train()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS_TRANSLATION+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer, val_dataloader)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    \n",
    "torch.save(transformer.state_dict(), \"pretrained_transformer.pth\")"
   ],
   "id": "ec42980941fb18dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.130, Val loss: 4.754, Epoch time = 0.975s\n",
      "Epoch: 2, Train loss: 4.450, Val loss: 4.386, Epoch time = 0.772s\n",
      "Epoch: 3, Train loss: 4.128, Val loss: 4.246, Epoch time = 0.752s\n",
      "Epoch: 4, Train loss: 3.846, Val loss: 4.156, Epoch time = 0.753s\n",
      "Epoch: 5, Train loss: 3.653, Val loss: 4.043, Epoch time = 0.749s\n",
      "Epoch: 6, Train loss: 3.426, Val loss: 3.918, Epoch time = 0.758s\n",
      "Epoch: 7, Train loss: 3.266, Val loss: 3.837, Epoch time = 0.755s\n",
      "Epoch: 8, Train loss: 3.114, Val loss: 3.836, Epoch time = 0.759s\n",
      "Epoch: 9, Train loss: 3.004, Val loss: 3.803, Epoch time = 0.757s\n",
      "Epoch: 10, Train loss: 2.922, Val loss: 4.002, Epoch time = 0.761s\n",
      "Epoch: 11, Train loss: 2.762, Val loss: 3.813, Epoch time = 0.757s\n",
      "Epoch: 12, Train loss: 2.607, Val loss: 3.670, Epoch time = 0.763s\n",
      "Epoch: 13, Train loss: 2.477, Val loss: 3.669, Epoch time = 0.755s\n",
      "Epoch: 14, Train loss: 2.357, Val loss: 3.695, Epoch time = 0.763s\n",
      "Epoch: 15, Train loss: 2.263, Val loss: 3.664, Epoch time = 0.762s\n",
      "Epoch: 16, Train loss: 2.164, Val loss: 3.602, Epoch time = 0.765s\n",
      "Epoch: 17, Train loss: 2.060, Val loss: 3.580, Epoch time = 0.768s\n",
      "Epoch: 18, Train loss: 1.987, Val loss: 3.582, Epoch time = 0.761s\n",
      "Epoch: 19, Train loss: 1.901, Val loss: 3.602, Epoch time = 0.759s\n",
      "Epoch: 20, Train loss: 1.817, Val loss: 3.596, Epoch time = 0.757s\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:10:34.444903Z",
     "start_time": "2024-10-14T19:10:32.660740Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Your BLEU score is: \" + str(bleu_evaluation(transformer, test_iter)))",
   "id": "31af1f0ad6357d84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czy my razem podróż samochód chcieć - Czy razem razem razem samochód ?\n",
      "Ja mama odwiedzić będzie - Ja będzie będzie będzie .\n",
      "Ty zły czemu - Ty Ty ?\n",
      "Ja góry zdobywać chcieć - Ja Ja ?\n",
      "Ty sklep iść? - Ty Ty ?\n",
      "Ty książka czytać ukończyć jeszcze - Ty jeszcze jeszcze jeszcze ?\n",
      "Ty rower park jechać byli? - Ty mają jesteś byli byli ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Projects\\pythonProject4\\venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "E:\\Python\\Projects\\pythonProject4\\venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "E:\\Python\\Projects\\pythonProject4\\venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On wysoki człowiek być - On ty być być .\n",
      "Ja się dobrze czuć. - Ja się dobrze .\n",
      "Ty na mnie zły być teraz? - Ty na mnie być teraz teraz ?\n",
      "Ja dobrze - Ja dobrze .\n",
      "Ty rower jeździć? - Ty ?\n",
      "Ty mi pomożesz? - Ty mi ?\n",
      "Ja telefon nowy kupić planować - Ja Ja kiedy ciocia ?\n",
      "Ona poniedziałek wolne mieć - Ona mam mieć ?\n",
      "On pomóc praca wczoraj byli. - On On , kto byli .\n",
      "Ja kawa pić zawsze - Ja długo zawsze ?\n",
      "My razem film oglądać - Ty razem razem .\n",
      "Ty woda pić? - Ty ?\n",
      "Jaką muzyka najbardziej lubić - Jest najbardziej najbardziej ?\n",
      "Ty szukać hotel co? - Ty ? raz co ?\n",
      "Dziadek na rower jeździć codziennie - Czy na zawsze ?\n",
      "Księżyc jasny dzisiaj - ?\n",
      "Kiedy zaczynać ten koncert - Kiedy ten ten ?\n",
      "On muzyka grać - On On ?\n",
      "Ty pomóc ja pytanie - Ty ja ja ?\n",
      "Ty zmęczony wyglądać - Ty ?\n",
      "Książka na stole leżeć - Myślę na stole ?\n",
      "On uśmiechać się - On się i ?\n",
      "Czy ona teatr weekend iść - Czy ona raz ?\n",
      "Drzewo park rosnąć - Teraz ?\n",
      "Twoja rodzina muzeum odwiedzać chciała? - Nigdy ty ty ty ?\n",
      "My tata nowy dom kupić chcieć - Chcę on czym dom mnie ?\n",
      "Dzieci plac zabawa bawić się - Jak ?\n",
      "Oni raz w miesiąc razem spotykać - Jak raz w razem razem .\n",
      "Ja czas na relaks mieć. - Ja czas na mnie .\n",
      "Ty dom mieć? - Ty czym ?\n",
      "On laptop nowy kupić zeszły miesiąc - On On tak kto jeszcze ?\n",
      "Książki na półka stać. - Jak na mają .\n",
      "Oni często do park spacerować - Jest do ona do .\n",
      "Ona samochód naprawa potrzebować - Ona raz ?\n",
      "Ja piosenka śpiewać - Ja Ja ?\n",
      "Ja komputer pracować - Ja Ja ?\n",
      "Ty mnie nie rozumieć. - Ty mnie nie mnie .\n",
      "Ty muzyka słuchać - Ty jesteś .\n",
      "Ona lubić tańczyć muzyka - Ona mnie ?\n",
      "Ja chory czuję już - Ja Ja już ?\n",
      "Dlaczego ty mnie odwiedzać nie? - Dlaczego ty mnie nie ?\n",
      "On obietnice swoje dotrzymać zawsze - On swoje swoje zawsze ?\n",
      "Ja biec szybki - Ja Ja ?\n",
      "Your BLEU score is: 1.2031483774573562e-155\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:10:34.452306Z",
     "start_time": "2024-10-14T19:10:34.445033Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d8da8cb4500394b7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:10:34.465504Z",
     "start_time": "2024-10-14T19:10:34.454392Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8145b00f53077d47",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
