{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 1740,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.034482758620689655,
      "grad_norm": 276.2572326660156,
      "learning_rate": 2.989655172413793e-05,
      "loss": 17.8186,
      "step": 10
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 122.16004943847656,
      "learning_rate": 2.9793103448275863e-05,
      "loss": 14.6441,
      "step": 20
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 239.99253845214844,
      "learning_rate": 2.9689655172413792e-05,
      "loss": 11.472,
      "step": 30
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 43.99583053588867,
      "learning_rate": 2.9586206896551724e-05,
      "loss": 9.3854,
      "step": 40
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 27.21590232849121,
      "learning_rate": 2.9482758620689654e-05,
      "loss": 8.157,
      "step": 50
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 81.87810516357422,
      "learning_rate": 2.9379310344827586e-05,
      "loss": 6.9506,
      "step": 60
    },
    {
      "epoch": 0.2413793103448276,
      "grad_norm": 36.209068298339844,
      "learning_rate": 2.9275862068965515e-05,
      "loss": 5.9708,
      "step": 70
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 13.583611488342285,
      "learning_rate": 2.9172413793103448e-05,
      "loss": 5.234,
      "step": 80
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 13.025290489196777,
      "learning_rate": 2.906896551724138e-05,
      "loss": 4.8178,
      "step": 90
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 9.057842254638672,
      "learning_rate": 2.8965517241379313e-05,
      "loss": 4.3406,
      "step": 100
    },
    {
      "epoch": 0.3793103448275862,
      "grad_norm": 11.476460456848145,
      "learning_rate": 2.8862068965517243e-05,
      "loss": 3.9152,
      "step": 110
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 37.875125885009766,
      "learning_rate": 2.8758620689655175e-05,
      "loss": 3.818,
      "step": 120
    },
    {
      "epoch": 0.4482758620689655,
      "grad_norm": 10.59254264831543,
      "learning_rate": 2.8655172413793104e-05,
      "loss": 3.327,
      "step": 130
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 17.076871871948242,
      "learning_rate": 2.8551724137931037e-05,
      "loss": 2.9582,
      "step": 140
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 20.463472366333008,
      "learning_rate": 2.8448275862068966e-05,
      "loss": 2.952,
      "step": 150
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 5.125356197357178,
      "learning_rate": 2.83448275862069e-05,
      "loss": 2.6354,
      "step": 160
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 7.940031051635742,
      "learning_rate": 2.8241379310344828e-05,
      "loss": 2.6232,
      "step": 170
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 5.8266215324401855,
      "learning_rate": 2.813793103448276e-05,
      "loss": 2.4008,
      "step": 180
    },
    {
      "epoch": 0.6551724137931034,
      "grad_norm": 4.254656791687012,
      "learning_rate": 2.803448275862069e-05,
      "loss": 2.3021,
      "step": 190
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 5.461121082305908,
      "learning_rate": 2.793103448275862e-05,
      "loss": 2.169,
      "step": 200
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 9.3993501663208,
      "learning_rate": 2.782758620689655e-05,
      "loss": 2.1075,
      "step": 210
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 3.3809587955474854,
      "learning_rate": 2.772413793103448e-05,
      "loss": 2.0039,
      "step": 220
    },
    {
      "epoch": 0.7931034482758621,
      "grad_norm": 3.4268722534179688,
      "learning_rate": 2.7620689655172413e-05,
      "loss": 1.7463,
      "step": 230
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 3.4401743412017822,
      "learning_rate": 2.7517241379310343e-05,
      "loss": 1.805,
      "step": 240
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 4.1269121170043945,
      "learning_rate": 2.741379310344828e-05,
      "loss": 1.8206,
      "step": 250
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 3.448606014251709,
      "learning_rate": 2.7310344827586208e-05,
      "loss": 1.8092,
      "step": 260
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 3.630561351776123,
      "learning_rate": 2.720689655172414e-05,
      "loss": 1.7153,
      "step": 270
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 4.856337547302246,
      "learning_rate": 2.710344827586207e-05,
      "loss": 1.6291,
      "step": 280
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.8016176223754883,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.5911,
      "step": 290
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9125505089759827,
      "eval_runtime": 4.3475,
      "eval_samples_per_second": 114.087,
      "eval_steps_per_second": 14.261,
      "step": 290
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 5.67767858505249,
      "learning_rate": 2.689655172413793e-05,
      "loss": 1.5311,
      "step": 300
    },
    {
      "epoch": 1.0689655172413792,
      "grad_norm": 3.1293606758117676,
      "learning_rate": 2.6793103448275864e-05,
      "loss": 1.4299,
      "step": 310
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 3.1372487545013428,
      "learning_rate": 2.6689655172413793e-05,
      "loss": 1.3236,
      "step": 320
    },
    {
      "epoch": 1.1379310344827587,
      "grad_norm": 3.480272054672241,
      "learning_rate": 2.6586206896551726e-05,
      "loss": 1.3513,
      "step": 330
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 2.7437236309051514,
      "learning_rate": 2.6482758620689655e-05,
      "loss": 1.2804,
      "step": 340
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 3.1405439376831055,
      "learning_rate": 2.6379310344827588e-05,
      "loss": 1.2064,
      "step": 350
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 2.8374154567718506,
      "learning_rate": 2.6275862068965517e-05,
      "loss": 1.3399,
      "step": 360
    },
    {
      "epoch": 1.2758620689655173,
      "grad_norm": 2.437802314758301,
      "learning_rate": 2.6172413793103446e-05,
      "loss": 1.156,
      "step": 370
    },
    {
      "epoch": 1.3103448275862069,
      "grad_norm": 3.2108778953552246,
      "learning_rate": 2.606896551724138e-05,
      "loss": 1.1967,
      "step": 380
    },
    {
      "epoch": 1.3448275862068966,
      "grad_norm": 3.3027756214141846,
      "learning_rate": 2.5965517241379308e-05,
      "loss": 1.1173,
      "step": 390
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 3.2330334186553955,
      "learning_rate": 2.586206896551724e-05,
      "loss": 1.1014,
      "step": 400
    },
    {
      "epoch": 1.4137931034482758,
      "grad_norm": 4.351698398590088,
      "learning_rate": 2.5758620689655173e-05,
      "loss": 1.0497,
      "step": 410
    },
    {
      "epoch": 1.4482758620689655,
      "grad_norm": 3.1567471027374268,
      "learning_rate": 2.5655172413793106e-05,
      "loss": 1.1031,
      "step": 420
    },
    {
      "epoch": 1.4827586206896552,
      "grad_norm": 2.479301691055298,
      "learning_rate": 2.5551724137931035e-05,
      "loss": 1.0048,
      "step": 430
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 2.899066209793091,
      "learning_rate": 2.5448275862068968e-05,
      "loss": 0.996,
      "step": 440
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 2.614063024520874,
      "learning_rate": 2.5344827586206897e-05,
      "loss": 0.998,
      "step": 450
    },
    {
      "epoch": 1.5862068965517242,
      "grad_norm": 3.324899196624756,
      "learning_rate": 2.524137931034483e-05,
      "loss": 0.9551,
      "step": 460
    },
    {
      "epoch": 1.6206896551724137,
      "grad_norm": 4.6895432472229,
      "learning_rate": 2.513793103448276e-05,
      "loss": 0.9139,
      "step": 470
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 2.686446189880371,
      "learning_rate": 2.503448275862069e-05,
      "loss": 0.8053,
      "step": 480
    },
    {
      "epoch": 1.6896551724137931,
      "grad_norm": 2.603376865386963,
      "learning_rate": 2.493103448275862e-05,
      "loss": 0.8861,
      "step": 490
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 2.599391222000122,
      "learning_rate": 2.4827586206896553e-05,
      "loss": 0.8525,
      "step": 500
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 2.9128458499908447,
      "learning_rate": 2.4724137931034483e-05,
      "loss": 0.7843,
      "step": 510
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 2.665677785873413,
      "learning_rate": 2.4620689655172415e-05,
      "loss": 0.8469,
      "step": 520
    },
    {
      "epoch": 1.8275862068965516,
      "grad_norm": 2.1016788482666016,
      "learning_rate": 2.4517241379310344e-05,
      "loss": 0.7661,
      "step": 530
    },
    {
      "epoch": 1.8620689655172413,
      "grad_norm": 2.7944552898406982,
      "learning_rate": 2.4413793103448277e-05,
      "loss": 0.7628,
      "step": 540
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 2.041457414627075,
      "learning_rate": 2.4310344827586206e-05,
      "loss": 0.7512,
      "step": 550
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 3.299072504043579,
      "learning_rate": 2.4206896551724135e-05,
      "loss": 0.7914,
      "step": 560
    },
    {
      "epoch": 1.9655172413793105,
      "grad_norm": 2.8633992671966553,
      "learning_rate": 2.410344827586207e-05,
      "loss": 0.7425,
      "step": 570
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.3862287998199463,
      "learning_rate": 2.4e-05,
      "loss": 0.7763,
      "step": 580
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.3818703889846802,
      "eval_runtime": 4.3659,
      "eval_samples_per_second": 113.608,
      "eval_steps_per_second": 14.201,
      "step": 580
    },
    {
      "epoch": 2.0344827586206895,
      "grad_norm": 2.403352975845337,
      "learning_rate": 2.3896551724137933e-05,
      "loss": 0.7946,
      "step": 590
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 4.3287272453308105,
      "learning_rate": 2.3793103448275862e-05,
      "loss": 0.7391,
      "step": 600
    },
    {
      "epoch": 2.103448275862069,
      "grad_norm": 2.7678956985473633,
      "learning_rate": 2.3689655172413795e-05,
      "loss": 0.7199,
      "step": 610
    },
    {
      "epoch": 2.1379310344827585,
      "grad_norm": 2.1640639305114746,
      "learning_rate": 2.3586206896551724e-05,
      "loss": 0.7052,
      "step": 620
    },
    {
      "epoch": 2.1724137931034484,
      "grad_norm": 3.1496694087982178,
      "learning_rate": 2.3482758620689657e-05,
      "loss": 0.7003,
      "step": 630
    },
    {
      "epoch": 2.206896551724138,
      "grad_norm": 2.5351109504699707,
      "learning_rate": 2.3379310344827586e-05,
      "loss": 0.6817,
      "step": 640
    },
    {
      "epoch": 2.2413793103448274,
      "grad_norm": 3.2356913089752197,
      "learning_rate": 2.327586206896552e-05,
      "loss": 0.6423,
      "step": 650
    },
    {
      "epoch": 2.2758620689655173,
      "grad_norm": 2.1299972534179688,
      "learning_rate": 2.3172413793103448e-05,
      "loss": 0.6713,
      "step": 660
    },
    {
      "epoch": 2.310344827586207,
      "grad_norm": 1.9882302284240723,
      "learning_rate": 2.306896551724138e-05,
      "loss": 0.7057,
      "step": 670
    },
    {
      "epoch": 2.344827586206897,
      "grad_norm": 2.9634320735931396,
      "learning_rate": 2.296551724137931e-05,
      "loss": 0.6571,
      "step": 680
    },
    {
      "epoch": 2.3793103448275863,
      "grad_norm": 4.742016315460205,
      "learning_rate": 2.2862068965517242e-05,
      "loss": 0.7092,
      "step": 690
    },
    {
      "epoch": 2.413793103448276,
      "grad_norm": 1.9681010246276855,
      "learning_rate": 2.275862068965517e-05,
      "loss": 0.6836,
      "step": 700
    },
    {
      "epoch": 2.4482758620689653,
      "grad_norm": 2.0156021118164062,
      "learning_rate": 2.2655172413793104e-05,
      "loss": 0.6651,
      "step": 710
    },
    {
      "epoch": 2.4827586206896552,
      "grad_norm": 1.9134814739227295,
      "learning_rate": 2.2551724137931033e-05,
      "loss": 0.5973,
      "step": 720
    },
    {
      "epoch": 2.5172413793103448,
      "grad_norm": 2.3011162281036377,
      "learning_rate": 2.2448275862068966e-05,
      "loss": 0.6302,
      "step": 730
    },
    {
      "epoch": 2.5517241379310347,
      "grad_norm": 2.1771721839904785,
      "learning_rate": 2.23448275862069e-05,
      "loss": 0.7592,
      "step": 740
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 3.042861223220825,
      "learning_rate": 2.2241379310344828e-05,
      "loss": 0.7317,
      "step": 750
    },
    {
      "epoch": 2.6206896551724137,
      "grad_norm": 2.0440051555633545,
      "learning_rate": 2.213793103448276e-05,
      "loss": 0.5773,
      "step": 760
    },
    {
      "epoch": 2.655172413793103,
      "grad_norm": 2.352818250656128,
      "learning_rate": 2.203448275862069e-05,
      "loss": 0.7123,
      "step": 770
    },
    {
      "epoch": 2.689655172413793,
      "grad_norm": 2.210484504699707,
      "learning_rate": 2.1931034482758622e-05,
      "loss": 0.5787,
      "step": 780
    },
    {
      "epoch": 2.7241379310344827,
      "grad_norm": 2.763622283935547,
      "learning_rate": 2.182758620689655e-05,
      "loss": 0.5977,
      "step": 790
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 2.117356300354004,
      "learning_rate": 2.1724137931034484e-05,
      "loss": 0.6704,
      "step": 800
    },
    {
      "epoch": 2.793103448275862,
      "grad_norm": 2.328982353210449,
      "learning_rate": 2.1620689655172413e-05,
      "loss": 0.602,
      "step": 810
    },
    {
      "epoch": 2.8275862068965516,
      "grad_norm": 2.2628111839294434,
      "learning_rate": 2.1517241379310346e-05,
      "loss": 0.6366,
      "step": 820
    },
    {
      "epoch": 2.862068965517241,
      "grad_norm": 2.019306182861328,
      "learning_rate": 2.1413793103448275e-05,
      "loss": 0.63,
      "step": 830
    },
    {
      "epoch": 2.896551724137931,
      "grad_norm": 2.020827531814575,
      "learning_rate": 2.1310344827586208e-05,
      "loss": 0.6396,
      "step": 840
    },
    {
      "epoch": 2.9310344827586206,
      "grad_norm": 1.8009883165359497,
      "learning_rate": 2.1206896551724137e-05,
      "loss": 0.6261,
      "step": 850
    },
    {
      "epoch": 2.9655172413793105,
      "grad_norm": 2.526093006134033,
      "learning_rate": 2.110344827586207e-05,
      "loss": 0.6298,
      "step": 860
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.7082576751708984,
      "learning_rate": 2.1e-05,
      "loss": 0.6107,
      "step": 870
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.35338035225868225,
      "eval_runtime": 4.2753,
      "eval_samples_per_second": 116.015,
      "eval_steps_per_second": 14.502,
      "step": 870
    },
    {
      "epoch": 3.0344827586206895,
      "grad_norm": 2.195277690887451,
      "learning_rate": 2.089655172413793e-05,
      "loss": 0.6257,
      "step": 880
    },
    {
      "epoch": 3.0689655172413794,
      "grad_norm": 1.8541163206100464,
      "learning_rate": 2.0793103448275864e-05,
      "loss": 0.6096,
      "step": 890
    },
    {
      "epoch": 3.103448275862069,
      "grad_norm": 2.688720464706421,
      "learning_rate": 2.0689655172413797e-05,
      "loss": 0.5775,
      "step": 900
    },
    {
      "epoch": 3.1379310344827585,
      "grad_norm": 1.9353138208389282,
      "learning_rate": 2.0586206896551726e-05,
      "loss": 0.6167,
      "step": 910
    },
    {
      "epoch": 3.1724137931034484,
      "grad_norm": 1.7766413688659668,
      "learning_rate": 2.0482758620689655e-05,
      "loss": 0.5868,
      "step": 920
    },
    {
      "epoch": 3.206896551724138,
      "grad_norm": 2.0205888748168945,
      "learning_rate": 2.0379310344827588e-05,
      "loss": 0.5851,
      "step": 930
    },
    {
      "epoch": 3.2413793103448274,
      "grad_norm": 1.7931509017944336,
      "learning_rate": 2.0275862068965517e-05,
      "loss": 0.5661,
      "step": 940
    },
    {
      "epoch": 3.2758620689655173,
      "grad_norm": 1.9256454706192017,
      "learning_rate": 2.017241379310345e-05,
      "loss": 0.5914,
      "step": 950
    },
    {
      "epoch": 3.310344827586207,
      "grad_norm": 2.2062900066375732,
      "learning_rate": 2.006896551724138e-05,
      "loss": 0.5543,
      "step": 960
    },
    {
      "epoch": 3.344827586206897,
      "grad_norm": 1.8681516647338867,
      "learning_rate": 1.996551724137931e-05,
      "loss": 0.546,
      "step": 970
    },
    {
      "epoch": 3.3793103448275863,
      "grad_norm": 2.8868393898010254,
      "learning_rate": 1.986206896551724e-05,
      "loss": 0.6199,
      "step": 980
    },
    {
      "epoch": 3.413793103448276,
      "grad_norm": 2.2933804988861084,
      "learning_rate": 1.9758620689655173e-05,
      "loss": 0.5973,
      "step": 990
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 2.6945042610168457,
      "learning_rate": 1.9655172413793102e-05,
      "loss": 0.5961,
      "step": 1000
    },
    {
      "epoch": 3.4827586206896552,
      "grad_norm": 2.184697389602661,
      "learning_rate": 1.9551724137931035e-05,
      "loss": 0.6533,
      "step": 1010
    },
    {
      "epoch": 3.5172413793103448,
      "grad_norm": 2.1128292083740234,
      "learning_rate": 1.9448275862068964e-05,
      "loss": 0.5723,
      "step": 1020
    },
    {
      "epoch": 3.5517241379310347,
      "grad_norm": 2.5843803882598877,
      "learning_rate": 1.9344827586206897e-05,
      "loss": 0.5816,
      "step": 1030
    },
    {
      "epoch": 3.586206896551724,
      "grad_norm": 1.7154980897903442,
      "learning_rate": 1.9241379310344826e-05,
      "loss": 0.5847,
      "step": 1040
    },
    {
      "epoch": 3.6206896551724137,
      "grad_norm": 2.020280122756958,
      "learning_rate": 1.9137931034482762e-05,
      "loss": 0.5222,
      "step": 1050
    },
    {
      "epoch": 3.655172413793103,
      "grad_norm": 2.4954402446746826,
      "learning_rate": 1.903448275862069e-05,
      "loss": 0.5418,
      "step": 1060
    },
    {
      "epoch": 3.689655172413793,
      "grad_norm": 1.9364923238754272,
      "learning_rate": 1.8931034482758624e-05,
      "loss": 0.6092,
      "step": 1070
    },
    {
      "epoch": 3.7241379310344827,
      "grad_norm": 2.574765205383301,
      "learning_rate": 1.8827586206896553e-05,
      "loss": 0.5641,
      "step": 1080
    },
    {
      "epoch": 3.7586206896551726,
      "grad_norm": 1.903506875038147,
      "learning_rate": 1.8724137931034482e-05,
      "loss": 0.5694,
      "step": 1090
    },
    {
      "epoch": 3.793103448275862,
      "grad_norm": 2.0137569904327393,
      "learning_rate": 1.8620689655172415e-05,
      "loss": 0.5884,
      "step": 1100
    },
    {
      "epoch": 3.8275862068965516,
      "grad_norm": 1.9721812009811401,
      "learning_rate": 1.8517241379310344e-05,
      "loss": 0.5441,
      "step": 1110
    },
    {
      "epoch": 3.862068965517241,
      "grad_norm": 2.2884483337402344,
      "learning_rate": 1.8413793103448277e-05,
      "loss": 0.4943,
      "step": 1120
    },
    {
      "epoch": 3.896551724137931,
      "grad_norm": 2.200462818145752,
      "learning_rate": 1.8310344827586206e-05,
      "loss": 0.6216,
      "step": 1130
    },
    {
      "epoch": 3.9310344827586206,
      "grad_norm": 2.555917263031006,
      "learning_rate": 1.820689655172414e-05,
      "loss": 0.4854,
      "step": 1140
    },
    {
      "epoch": 3.9655172413793105,
      "grad_norm": 1.387213110923767,
      "learning_rate": 1.8103448275862068e-05,
      "loss": 0.5255,
      "step": 1150
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.8498268127441406,
      "learning_rate": 1.8e-05,
      "loss": 0.5282,
      "step": 1160
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.33889487385749817,
      "eval_runtime": 4.2465,
      "eval_samples_per_second": 116.803,
      "eval_steps_per_second": 14.6,
      "step": 1160
    },
    {
      "epoch": 4.0344827586206895,
      "grad_norm": 1.8938965797424316,
      "learning_rate": 1.789655172413793e-05,
      "loss": 0.4774,
      "step": 1170
    },
    {
      "epoch": 4.068965517241379,
      "grad_norm": 1.8307021856307983,
      "learning_rate": 1.7793103448275862e-05,
      "loss": 0.5585,
      "step": 1180
    },
    {
      "epoch": 4.103448275862069,
      "grad_norm": 2.044658660888672,
      "learning_rate": 1.768965517241379e-05,
      "loss": 0.5461,
      "step": 1190
    },
    {
      "epoch": 4.137931034482759,
      "grad_norm": 1.8888202905654907,
      "learning_rate": 1.7586206896551724e-05,
      "loss": 0.5206,
      "step": 1200
    },
    {
      "epoch": 4.172413793103448,
      "grad_norm": 2.278452157974243,
      "learning_rate": 1.7482758620689657e-05,
      "loss": 0.4929,
      "step": 1210
    },
    {
      "epoch": 4.206896551724138,
      "grad_norm": 1.5828956365585327,
      "learning_rate": 1.737931034482759e-05,
      "loss": 0.5345,
      "step": 1220
    },
    {
      "epoch": 4.241379310344827,
      "grad_norm": 2.0260307788848877,
      "learning_rate": 1.727586206896552e-05,
      "loss": 0.5134,
      "step": 1230
    },
    {
      "epoch": 4.275862068965517,
      "grad_norm": 1.8078182935714722,
      "learning_rate": 1.717241379310345e-05,
      "loss": 0.4772,
      "step": 1240
    },
    {
      "epoch": 4.310344827586207,
      "grad_norm": 1.8981380462646484,
      "learning_rate": 1.706896551724138e-05,
      "loss": 0.539,
      "step": 1250
    },
    {
      "epoch": 4.344827586206897,
      "grad_norm": 2.3650403022766113,
      "learning_rate": 1.6965517241379313e-05,
      "loss": 0.5448,
      "step": 1260
    },
    {
      "epoch": 4.379310344827586,
      "grad_norm": 2.018930673599243,
      "learning_rate": 1.6862068965517242e-05,
      "loss": 0.5329,
      "step": 1270
    },
    {
      "epoch": 4.413793103448276,
      "grad_norm": 1.8318253755569458,
      "learning_rate": 1.675862068965517e-05,
      "loss": 0.5534,
      "step": 1280
    },
    {
      "epoch": 4.448275862068965,
      "grad_norm": 1.9619290828704834,
      "learning_rate": 1.6655172413793104e-05,
      "loss": 0.499,
      "step": 1290
    },
    {
      "epoch": 4.482758620689655,
      "grad_norm": 2.39422607421875,
      "learning_rate": 1.6551724137931033e-05,
      "loss": 0.5254,
      "step": 1300
    },
    {
      "epoch": 4.517241379310345,
      "grad_norm": 1.9609456062316895,
      "learning_rate": 1.6448275862068966e-05,
      "loss": 0.4518,
      "step": 1310
    },
    {
      "epoch": 4.551724137931035,
      "grad_norm": 2.037442922592163,
      "learning_rate": 1.6344827586206895e-05,
      "loss": 0.6027,
      "step": 1320
    },
    {
      "epoch": 4.586206896551724,
      "grad_norm": 1.9001809358596802,
      "learning_rate": 1.6241379310344828e-05,
      "loss": 0.484,
      "step": 1330
    },
    {
      "epoch": 4.620689655172414,
      "grad_norm": 1.762337327003479,
      "learning_rate": 1.6137931034482757e-05,
      "loss": 0.485,
      "step": 1340
    },
    {
      "epoch": 4.655172413793103,
      "grad_norm": 2.2305095195770264,
      "learning_rate": 1.603448275862069e-05,
      "loss": 0.5602,
      "step": 1350
    },
    {
      "epoch": 4.689655172413794,
      "grad_norm": 1.8438562154769897,
      "learning_rate": 1.593103448275862e-05,
      "loss": 0.55,
      "step": 1360
    },
    {
      "epoch": 4.724137931034483,
      "grad_norm": 1.9347730875015259,
      "learning_rate": 1.5827586206896555e-05,
      "loss": 0.496,
      "step": 1370
    },
    {
      "epoch": 4.758620689655173,
      "grad_norm": 2.2279152870178223,
      "learning_rate": 1.5724137931034484e-05,
      "loss": 0.5669,
      "step": 1380
    },
    {
      "epoch": 4.793103448275862,
      "grad_norm": 2.007535696029663,
      "learning_rate": 1.5620689655172417e-05,
      "loss": 0.5535,
      "step": 1390
    },
    {
      "epoch": 4.827586206896552,
      "grad_norm": 1.9370028972625732,
      "learning_rate": 1.5517241379310346e-05,
      "loss": 0.472,
      "step": 1400
    },
    {
      "epoch": 4.862068965517241,
      "grad_norm": 1.9464740753173828,
      "learning_rate": 1.541379310344828e-05,
      "loss": 0.5106,
      "step": 1410
    },
    {
      "epoch": 4.896551724137931,
      "grad_norm": 1.2063729763031006,
      "learning_rate": 1.5310344827586208e-05,
      "loss": 0.476,
      "step": 1420
    },
    {
      "epoch": 4.931034482758621,
      "grad_norm": 2.083547592163086,
      "learning_rate": 1.5206896551724139e-05,
      "loss": 0.5339,
      "step": 1430
    },
    {
      "epoch": 4.9655172413793105,
      "grad_norm": 1.39006769657135,
      "learning_rate": 1.510344827586207e-05,
      "loss": 0.4744,
      "step": 1440
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.0486669540405273,
      "learning_rate": 1.5e-05,
      "loss": 0.4748,
      "step": 1450
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.33299458026885986,
      "eval_runtime": 4.2425,
      "eval_samples_per_second": 116.911,
      "eval_steps_per_second": 14.614,
      "step": 1450
    },
    {
      "epoch": 5.0344827586206895,
      "grad_norm": 2.1905367374420166,
      "learning_rate": 1.4896551724137931e-05,
      "loss": 0.4689,
      "step": 1460
    },
    {
      "epoch": 5.068965517241379,
      "grad_norm": 1.3387997150421143,
      "learning_rate": 1.4793103448275862e-05,
      "loss": 0.4575,
      "step": 1470
    },
    {
      "epoch": 5.103448275862069,
      "grad_norm": 1.3608781099319458,
      "learning_rate": 1.4689655172413793e-05,
      "loss": 0.4147,
      "step": 1480
    },
    {
      "epoch": 5.137931034482759,
      "grad_norm": 2.0162105560302734,
      "learning_rate": 1.4586206896551724e-05,
      "loss": 0.4749,
      "step": 1490
    },
    {
      "epoch": 5.172413793103448,
      "grad_norm": 1.8144288063049316,
      "learning_rate": 1.4482758620689657e-05,
      "loss": 0.4465,
      "step": 1500
    },
    {
      "epoch": 5.206896551724138,
      "grad_norm": 2.064601421356201,
      "learning_rate": 1.4379310344827588e-05,
      "loss": 0.4935,
      "step": 1510
    },
    {
      "epoch": 5.241379310344827,
      "grad_norm": 2.0107460021972656,
      "learning_rate": 1.4275862068965518e-05,
      "loss": 0.5099,
      "step": 1520
    },
    {
      "epoch": 5.275862068965517,
      "grad_norm": 1.8542262315750122,
      "learning_rate": 1.417241379310345e-05,
      "loss": 0.4405,
      "step": 1530
    },
    {
      "epoch": 5.310344827586207,
      "grad_norm": 1.3142104148864746,
      "learning_rate": 1.406896551724138e-05,
      "loss": 0.4834,
      "step": 1540
    },
    {
      "epoch": 5.344827586206897,
      "grad_norm": 2.4617908000946045,
      "learning_rate": 1.396551724137931e-05,
      "loss": 0.4633,
      "step": 1550
    },
    {
      "epoch": 5.379310344827586,
      "grad_norm": 3.3979625701904297,
      "learning_rate": 1.386206896551724e-05,
      "loss": 0.5269,
      "step": 1560
    },
    {
      "epoch": 5.413793103448276,
      "grad_norm": 2.1018669605255127,
      "learning_rate": 1.3758620689655171e-05,
      "loss": 0.5407,
      "step": 1570
    },
    {
      "epoch": 5.448275862068965,
      "grad_norm": 2.362607955932617,
      "learning_rate": 1.3655172413793104e-05,
      "loss": 0.4712,
      "step": 1580
    },
    {
      "epoch": 5.482758620689655,
      "grad_norm": 1.6330090761184692,
      "learning_rate": 1.3551724137931035e-05,
      "loss": 0.4801,
      "step": 1590
    },
    {
      "epoch": 5.517241379310345,
      "grad_norm": 1.7860747575759888,
      "learning_rate": 1.3448275862068966e-05,
      "loss": 0.4923,
      "step": 1600
    },
    {
      "epoch": 5.551724137931035,
      "grad_norm": 1.7136574983596802,
      "learning_rate": 1.3344827586206897e-05,
      "loss": 0.4456,
      "step": 1610
    },
    {
      "epoch": 5.586206896551724,
      "grad_norm": 2.307678699493408,
      "learning_rate": 1.3241379310344828e-05,
      "loss": 0.4906,
      "step": 1620
    },
    {
      "epoch": 5.620689655172414,
      "grad_norm": 1.5812584161758423,
      "learning_rate": 1.3137931034482759e-05,
      "loss": 0.5218,
      "step": 1630
    },
    {
      "epoch": 5.655172413793103,
      "grad_norm": 1.5990195274353027,
      "learning_rate": 1.303448275862069e-05,
      "loss": 0.4807,
      "step": 1640
    },
    {
      "epoch": 5.689655172413794,
      "grad_norm": 1.8816889524459839,
      "learning_rate": 1.293103448275862e-05,
      "loss": 0.4841,
      "step": 1650
    },
    {
      "epoch": 5.724137931034483,
      "grad_norm": 2.2701849937438965,
      "learning_rate": 1.2827586206896553e-05,
      "loss": 0.4605,
      "step": 1660
    },
    {
      "epoch": 5.758620689655173,
      "grad_norm": 1.7092385292053223,
      "learning_rate": 1.2724137931034484e-05,
      "loss": 0.4461,
      "step": 1670
    },
    {
      "epoch": 5.793103448275862,
      "grad_norm": 1.4247217178344727,
      "learning_rate": 1.2620689655172415e-05,
      "loss": 0.4617,
      "step": 1680
    },
    {
      "epoch": 5.827586206896552,
      "grad_norm": 1.9444457292556763,
      "learning_rate": 1.2517241379310346e-05,
      "loss": 0.543,
      "step": 1690
    },
    {
      "epoch": 5.862068965517241,
      "grad_norm": 1.6347044706344604,
      "learning_rate": 1.2413793103448277e-05,
      "loss": 0.464,
      "step": 1700
    },
    {
      "epoch": 5.896551724137931,
      "grad_norm": 1.682263731956482,
      "learning_rate": 1.2310344827586208e-05,
      "loss": 0.4541,
      "step": 1710
    },
    {
      "epoch": 5.931034482758621,
      "grad_norm": 1.5212535858154297,
      "learning_rate": 1.2206896551724138e-05,
      "loss": 0.5082,
      "step": 1720
    },
    {
      "epoch": 5.9655172413793105,
      "grad_norm": 2.1949868202209473,
      "learning_rate": 1.2103448275862068e-05,
      "loss": 0.5166,
      "step": 1730
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.2106454372406006,
      "learning_rate": 1.2e-05,
      "loss": 0.4847,
      "step": 1740
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.33000561594963074,
      "eval_runtime": 4.2298,
      "eval_samples_per_second": 117.263,
      "eval_steps_per_second": 14.658,
      "step": 1740
    }
  ],
  "logging_steps": 10,
  "max_steps": 2900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4104398127366144.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
