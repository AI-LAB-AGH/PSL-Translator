{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l66yjOwCSaIa",
        "outputId": "60d07e02-647a-48b8-c913-ad58a139973a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PsXeM5KIsPrC"
      },
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_name = \"allegro/plt5-base\""
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uElbBMl6LQE"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, file_paths, reverse=False, transform=None, target_transform=None):\n",
        "        def read_from_file(file_path):\n",
        "            with open(file_path, \"r\", encoding=\"UTF-8\") as f:\n",
        "                for i, line in enumerate(f):\n",
        "                    if i % 2 == 0:\n",
        "                        self.data.append([line.strip()])\n",
        "                    else:\n",
        "                        self.data[-1].append(line.strip())\n",
        "\n",
        "        self.data = []\n",
        "        self.back = reverse\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        if type(file_paths) is str:\n",
        "            read_from_file(file_paths)\n",
        "        elif type(file_paths) in (list, tuple):\n",
        "            for file_path in file_paths:\n",
        "                read_from_file(file_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx][0]\n",
        "        target = self.data[idx][1]\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "        if self.back:\n",
        "            return target, sample\n",
        "        else:\n",
        "            return sample, target\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "244805af76a84bb38095849d01f2abed",
            "2d092a95057a408e991c54ad6fdab05e",
            "24de4b1003f241188c45a47c74cfae04",
            "84f0e725714d421da33201a7865df480",
            "f01e7d463a944b9d9793c09c335d2cab",
            "f7a6c82dc96541698526e2170401efd8",
            "d8d962dfb95248a2b44f0a900a5c5162",
            "ca7b30312468402cbab9e85d5abfa8f8",
            "d1e45700a03c4aa2a6747f4f74db0f80",
            "8d104962739f45a4b7c0177ab504ca62",
            "eadc84de6f764f938674d6b81355fbce"
          ]
        },
        "id": "8BhaqURs5ymQ",
        "outputId": "1f42ce7c-d9ef-4cef-964e-050314fa3e3f"
      },
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
        "import torch\n",
        "import os\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Load the tokenizer and model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "for param in model.parameters():\n",
        "  param.data = param.data.contiguous()\n",
        "\n",
        "# Define a function to tokenize the inputs\n",
        "def tokenize_function(sample_target_pair):\n",
        "    sample, target = sample_target_pair\n",
        "    model_inputs = tokenizer(sample, max_length=16, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    labels = tokenizer(target, max_length=16, truncation=True, padding=\"max_length\", return_tensors=\"pt\").input_ids\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "    model_inputs[\"labels\"] = labels\n",
        "    for key in model_inputs:\n",
        "        model_inputs[key] = model_inputs[key].view(-1)\n",
        "    return model_inputs\n",
        "\n",
        "def tokenize(dataset):\n",
        "  return  [tokenize_function(pair) for pair in dataset]\n",
        "\n",
        "\n",
        "# Load your custom dataset\n",
        "train_translation = TranslationDataset(\"/content/drive/MyDrive/PSL-Translator/data.txt\")\n",
        "val_translation = TranslationDataset(\"/content/drive/MyDrive/PSL-Translator/val_data.txt\")\n",
        "train_translation = tokenize(train_translation)\n",
        "val_translation = tokenize(val_translation)\n",
        "\n",
        "# Define data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"/content/drive/MyDrive/PSL-Translator/{model_name}\",  # output directory\n",
        "    evaluation_strategy=\"epoch\",  # evaluation during each epoch\n",
        "    learning_rate=3e-5,  # learning rate\n",
        "    per_device_train_batch_size=8,  # batch size\n",
        "    per_device_eval_batch_size=8,  # evaluation batch size\n",
        "    weight_decay=0.01,  # weight decay for regularization\n",
        "    save_total_limit=2,  # limit total checkpoint saves\n",
        "    num_train_epochs=10,  # number of epochs to train        # enables text generation for evaluation\n",
        "    logging_dir=\"./logs\",  # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\",\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:  86%|########5 | 944M/1.10G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "244805af76a84bb38095849d01f2abed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cID2jDaAwqIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "22aca3ab-1747-42d1-cbd5-3343985713c7"
      },
      "source": [
        "# Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_translation,\n",
        "    eval_dataset=val_translation,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4422' max='11590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4422/11590 17:17 < 28:02, 4.26 it/s, Epoch 3.81/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.059400</td>\n",
              "      <td>1.134108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.204700</td>\n",
              "      <td>0.738685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.329700</td>\n",
              "      <td>0.642928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11590' max='11590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11590/11590 45:56, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.059400</td>\n",
              "      <td>1.134108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.204700</td>\n",
              "      <td>0.738685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.329700</td>\n",
              "      <td>0.642928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.191900</td>\n",
              "      <td>0.564664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.808400</td>\n",
              "      <td>0.528679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.866400</td>\n",
              "      <td>0.518459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.792700</td>\n",
              "      <td>0.497184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.623200</td>\n",
              "      <td>0.480969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.714900</td>\n",
              "      <td>0.490616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.732000</td>\n",
              "      <td>0.489613</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=11590, training_loss=1.386980284690034, metrics={'train_runtime': 2758.6284, 'train_samples_per_second': 33.607, 'train_steps_per_second': 4.201, 'total_flos': 2106359428055040.0, 'train_loss': 1.386980284690034, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s_gohlEn6O9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7fa837b7-eb8a-4f47-f579-b9225dca333c"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for data in val_translation:\n",
        "    outputs = model.generate(data['input_ids'].unsqueeze(0).to(\"cuda\"))\n",
        "    print(tokenizer.decode(data['input_ids'], skip_special_tokens=True))\n",
        "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ja wczoraj kino iÅ›Ä‡ byÅ‚o\n",
            "Wczoraj byÅ‚em w kinie\n",
            "Ty pies spacer kiedy?\n",
            "Czy wyprowadzasz psa na spacer?\n",
            "Ona ciasto piec umie\n",
            "Ona umie piec ciasto\n",
            "My dom duÅ¼y kupiÄ‡\n",
            "KupiliÅ›my duÅ¼y dom\n",
            "Dziecko szkoÅ‚a zaczyna dzisiaj\n",
            "Dziecko dzisiaj idzie do szkoÅ‚y\n",
            "Ja kawÄ™ lubiÄ‡ nie\n",
            "Nie lubiÄ™ kawy\n",
            "Ty rower naprawiÄ‡ kiedy?\n",
            "Czy naprawiÅ‚eÅ› rower?\n",
            "Ona zima narty jeÅºdzi\n",
            "Ona jeÅºdzi na nartach zimÄ…\n",
            "On koncert byÄ‡ jutro\n",
            "On jutro idzie na koncert\n",
            "My wakacje Grecja planowaÄ‡\n",
            "Planujemy wakacje w Grecji\n",
            "Ty kot mleko daÄ‡?\n",
            "Czy masz mleko kota?\n",
            "Ona telefon nowy kupiÄ‡\n",
            "Ona kupiÅ‚a nowy telefon\n",
            "Ja woda piÄ‡ duÅ¼o\n",
            "PijÄ™ duÅ¼o wody\n",
            "Dziecko plac zabaw bawiÄ‡\n",
            "Dziecko bawi siÄ™ na placu zabaw\n",
            "On samochÃ³d sprzedaÄ‡ miesiÄ…c temu\n",
            "On sprzedaÅ‚ samochÃ³d miesiÄ…c temu\n",
            "Ty Ä‡wiczyÄ‡ codziennie?\n",
            "Czy codziennie Ä‡wiczysz?\n",
            "Ona ksiÄ…Å¼ka czytaÄ‡ teraz\n",
            "Ona teraz czyta ksiÄ…Å¼kÄ™\n",
            "My film oglÄ…daÄ‡ wczoraj\n",
            "OglÄ…daliÅ›my film wczoraj\n",
            "Ty komputer naprawa skoÅ„czyÄ‡?\n",
            "SkoÅ„czyÅ‚eÅ› naprawiÄ‡ komputer?\n",
            "Ja podrÃ³Å¼ WÅ‚ochy planowaÄ‡\n",
            "PlanujÄ™ podrÃ³Å¼ do WÅ‚och\n",
            "Ty praca na jutro zrobiÄ‡?\n",
            "Czy zrobisz jutro coÅ›?\n",
            "Ona dzisiaj spacer park\n",
            "Ona dzisiaj spaceruje w parku\n",
            "On graÄ‡ w piÅ‚ka noÅ¼na\n",
            "On gra w piÅ‚kÄ™ noÅ¼nÄ…\n",
            "My kuchnia sprzÄ…taÄ‡ teraz\n",
            "SprzÄ…tamy teraz kuchniÄ™\n",
            "Ty ksiÄ…Å¼ki wypoÅ¼yczyÄ‡ biblioteka?\n",
            "Czy wypoÅ¼yczasz ksiÄ…Å¼ki z biblioteki?\n",
            "Ona ciasto piec teraz\n",
            "Ona piecze teraz ciasto\n",
            "Ja rower jeÅºdziÄ‡ co weekend\n",
            "Co weekend jeÅ¼dÅ¼Ä™ rowerem\n",
            "Ty szkoÅ‚a dzisiaj mieÄ‡?\n",
            "Czy idziesz dzisiaj do szkoÅ‚y?\n",
            "On mecz oglÄ…daÄ‡ wczoraj\n",
            "On oglÄ…daÅ‚ mecz wczoraj\n",
            "My samochÃ³d myÄ‡ teraz\n",
            "Myjemy teraz samochÃ³d\n",
            "Ja zimno lubiÄ‡ nie\n",
            "Nie lubiÄ™ zimna\n",
            "Ty uczyÄ‡ siÄ™ na egzamin?\n",
            "Uczysz siÄ™ na egzaminie?\n",
            "Ona biegaÄ‡ w parku\n",
            "Ona biega w parku\n",
            "On karmiÄ‡ ptaki codziennie\n",
            "On codziennie karmi ptaki\n",
            "My kuchnia gotowaÄ‡ wspÃ³lnie\n",
            "Gotujemy wspÃ³lnie w kuchni\n",
            "Ty graÄ‡ na gitarze umieÄ‡?\n",
            "Umiesz graÄ‡ na gitarze?\n",
            "Ona dom sprzÄ…taÄ‡ dzisiaj\n",
            "Ona sprzÄ…ta dom dzisiaj\n",
            "Ja chce nowa praca\n",
            "ChcÄ™ nowÄ… pracÄ™\n",
            "Ty rower naprawiaÄ‡ teraz?\n",
            "Naprawiasz teraz rower?\n",
            "On okulary nosiÄ‡ zawsze\n",
            "On zawsze nosi okulary\n",
            "My jezioro pÅ‚ywaÄ‡ latem\n",
            "PÅ‚ywamy w jeziorze latem\n",
            "Ty pracowaÄ‡ w domu teraz?\n",
            "Czy pracujesz teraz w domu?\n",
            "Ona muzyka sÅ‚uchaÄ‡ codziennie\n",
            "Ona codziennie sÅ‚ucha muzyki\n",
            "Ja zupa gotowaÄ‡ dzisiaj\n",
            "Dzisiaj gotujÄ™ zupÄ™\n",
            "Ty sen mieÄ‡ dobry?\n",
            "Czy masz dobry sen?\n",
            "On skakaÄ‡ przez pÅ‚ot wczoraj\n",
            "On skakaÅ‚ wczoraj przez pÅ‚ot\n",
            "My pies karmiÄ‡ codziennie\n",
            "Codziennie karmimy psa\n",
            "Ty przyjaciel spotkaÄ‡ w weekend?\n",
            "SpotkaÅ‚eÅ› przyjaciela w weekend?\n",
            "Ona film oglÄ…daÄ‡ teraz\n",
            "Ona teraz oglÄ…da film\n",
            "Ja jabÅ‚ko jeÅ›Ä‡ codziennie\n",
            "Codziennie jem jabÅ‚ko\n",
            "Ty zakupy zrobiÄ‡ dzisiaj?\n",
            "Czy robisz dzisiaj zakupy?\n",
            "On siÅ‚ownia Ä‡wiczyÄ‡ czÄ™sto\n",
            "On czÄ™sto Ä‡wiczy na siÅ‚owni\n",
            "My dom remontowaÄ‡ w tym roku\n",
            "Remontujemy dom w tym roku\n",
            "Ty zdjÄ™cie robiÄ‡ wakacje?\n",
            "Czy robisz zdjÄ™cia na wakacjach?\n",
            "Ona miasto zwiedzaÄ‡ latem\n",
            "Ona zwiedza miasto latem\n",
            "Ja sport uprawiaÄ‡ regularnie\n",
            "Regularnie uprawiam sport\n",
            "Ty telefon zgubiÄ‡?\n",
            "ZgubiÅ‚eÅ› telefon?\n",
            "Ona nowa sukienka kupiÄ‡\n",
            "Ona kupiÅ‚a nowÄ… sukienkÄ™\n",
            "On praca szukaÄ‡ teraz\n",
            "On szuka pracy teraz\n",
            "My kot nowy mieÄ‡\n",
            "Mamy nowego kota\n",
            "Ty rower naprawiaÄ‡ skoÅ„czyÄ‡?\n",
            "SkoÅ„czyÅ‚eÅ› naprawiÄ‡ rower?\n",
            "Ona piec ciasto nauczyÄ‡\n",
            "Ona nauczyÅ‚a siÄ™ piec ciasto\n",
            "On komputer naprawiÄ‡ koÅ„czyÄ‡\n",
            "On koÅ„czy naprawiÄ‡ komputer\n",
            "My wakacje planowaÄ‡ razem\n",
            "Planujemy razem wakacje\n",
            "Ty uczy siÄ™ jÄ™zyk nowy?\n",
            "Uczysz siÄ™ nowego jÄ™zyka?\n",
            "Ona biegaÄ‡ rano codziennie\n",
            "Ona codziennie biega rano\n",
            "Ja chleb piec dzisiaj\n",
            "PiekÄ™ dzisiaj chleb\n",
            "Ty kino zaplanowaÄ‡ kiedy?\n",
            "Kiedy zaplanujesz kino?\n",
            "On samochÃ³d myÄ‡ teraz\n",
            "On teraz myje samochÃ³d\n",
            "My dom sprzÄ…taÄ‡ co tydzieÅ„\n",
            "SprzÄ…tamy dom co tydzieÅ„\n",
            "Ty rower sprzedaÄ‡ planowaÄ‡?\n",
            "Planujesz sprzedaÄ‡ rower?\n",
            "Ona rower jeÅºdziÄ‡ park\n",
            "Ona jeÅºdzi rowerem po parku\n",
            "On ksiÄ…Å¼ka kupiÄ‡ nowa\n",
            "On kupiÅ‚ nowÄ… ksiÄ…Å¼kÄ™\n",
            "My film wspÃ³lnie oglÄ…daÄ‡ wczoraj\n",
            "OglÄ…daliÅ›my film wspÃ³lnie wczoraj\n",
            "Ty pies spacer codziennie?\n",
            "Codziennie spacerujesz z psem?\n",
            "Ona nowy samochÃ³d kupiÄ‡\n",
            "Ona kupiÅ‚a nowy samochÃ³d\n",
            "Ja komputer naprawiaÄ‡ teraz\n",
            "Naprawiam teraz komputer\n",
            "Ty dzisiaj obiad gotowaÄ‡?\n",
            "Czy gotujesz dzisiaj obiad?\n",
            "On praca zakoÅ„czyÄ‡ miesiÄ…c temu\n",
            "On zakoÅ„czyÅ‚ pracÄ™ miesiÄ…c temu\n",
            "My nowa ksiÄ…Å¼ka pisaÄ‡\n",
            "Piszemy nowÄ… ksiÄ…Å¼kÄ™\n",
            "Ty sport uprawiaÄ‡ regularnie?\n",
            "Czy regularnie uprawiasz sport?\n",
            "Ona dom sprzÄ…taÄ‡ co weekend\n",
            "Ona sprzÄ…ta dom co weekend\n",
            "Ja biegaÄ‡ park codziennie\n",
            "Codziennie biegam w parku\n",
            "Ty rower jeÅºdziÄ‡ praca?\n",
            "JeÅºdzisz na rowerze?\n",
            "On plaÅ¼a leÅ¼eÄ‡ teraz\n",
            "On teraz leÅ¼y na plaÅ¼y\n",
            "My graÄ‡ w piÅ‚ka wczoraj\n",
            "GraÅ‚yÅ›my wczoraj w piÅ‚kÄ™\n",
            "Ty woda piÄ‡ caÅ‚y dzieÅ„?\n",
            "Czy pijesz wodÄ™ caÅ‚y dzieÅ„?\n",
            "Ona nauka lubiÄ‡ bardzo\n",
            "Ona bardzo lubi naukÄ™\n",
            "On spacer las czÄ™sto\n",
            "On czÄ™sto spaceruje po lesie\n",
            "My kuchnia gotowaÄ‡ wspÃ³lnie\n",
            "Gotujemy wspÃ³lnie w kuchni\n",
            "Ty do szkoÅ‚y dzisiaj?\n",
            "Czy idziesz dzisiaj do szkoÅ‚y?\n",
            "Ona Å›piewaÄ‡ pod prysznic\n",
            "Ona Å›piewa pod prysznicem\n",
            "Ja film oglÄ…daÄ‡ wieczorem\n",
            "OglÄ…dam film wieczorem\n",
            "Ty wczoraj spacer park?\n",
            "Czy spacerowaÅ‚eÅ› wczoraj w parku?\n",
            "On biegaÄ‡ szybko zawsze\n",
            "On zawsze biega szybko\n",
            "My ksiÄ…Å¼ka wspÃ³lnie czytaÄ‡\n",
            "Czytamy ksiÄ…Å¼kÄ™ wspÃ³lnie\n",
            "Ty siÅ‚ownia Ä‡wiczyÄ‡ codziennie?\n",
            "Czy codziennie Ä‡wiczysz na siÅ‚owni?\n",
            "Ona kanapka zjeÅ›Ä‡ caÅ‚y\n",
            "Ona zjadÅ‚a caÅ‚Ä… kanapkÄ™\n",
            "Ja dom sprzÄ…taÄ‡\n",
            "SprzÄ…tam dom\n",
            "Ty obiad jeÅ›Ä‡ kiedy\n",
            "Kiedy gotujesz obiad?\n",
            "On park spacerowaÄ‡\n",
            "On spaceruje po parku\n",
            "DzieÅ„ dobry, jak siÄ™ masz?\n",
            "Jak siÄ™ masz?\n",
            "Ja na zakupy iÅ›Ä‡\n",
            "IdÄ™ na zakupy\n",
            "Mama ksiÄ…Å¼ka czytaÄ‡\n",
            "Mama czyta ksiÄ…Å¼kÄ™\n",
            "Kto wczoraj dzwoniÅ‚ telefon?\n",
            "Kto dzwoniÅ‚ wczoraj na telefon?\n",
            "Ja iÅ›Ä‡ szkoÅ‚a\n",
            "IdÄ™ do szkoÅ‚y\n",
            "On rower naprawiaÄ‡\n",
            "On naprawia rower\n",
            "Ty pÅ‚ywaÄ‡ umieÄ‡?\n",
            "Umiesz pÅ‚ywaÄ‡?\n",
            "Dziecko za duÅ¼e do wÃ³zek\n",
            "Dziecko jest duÅ¼e do wÃ³zka\n",
            "PiÄ™kne sÅ‚oÅ„ce dziÅ› Å›wieciÄ‡\n",
            "PiÄ™kne sÅ‚oÅ„ce Å›wieci dziÅ›\n",
            "Ja pies wyprowadzaÄ‡ teraz\n",
            "Wyprowadzam psa teraz\n",
            "TwÃ³j brat lubiÄ‡ czekolada\n",
            "Czy twÃ³j brat lubi czekoladÄ™?\n",
            "Gdzie kupiÄ‡ bilet na pociÄ…g?\n",
            "Gdzie kupiÅ‚eÅ› bilet na pociÄ…g?\n",
            "Praca trudna, ale satysfakcjonujÄ…ca\n",
            "Praca jest trudna, ale satysfakcjonujÄ…ca\n",
            "Ja wczoraj zjeÅ›Ä‡ ciasto\n",
            "Wczoraj piekÅ‚em ciasto\n",
            "LiÅ›cie na drzewach zmieniaÄ‡ kolor\n",
            "LiÅ›cie zmieniajÄ… kolor na drzewach\n",
            "Moja siostra graÄ‡ na gitara\n",
            "Moja siostra gra na gitarze\n",
            "Kiedy twÃ³j tata wracaÄ‡ do dom?\n",
            "Kiedy twÃ³j tata wraca do domu?\n",
            "Niebieski samochÃ³d szybko jechaÄ‡\n",
            "Niebieski samochÃ³d jedzie szybko\n",
            "On nie widzieÄ‡ gdzie iÅ›Ä‡\n",
            "Gdzie on nie widziaÅ‚\n",
            "Ja lubiÄ‡ oglÄ…daÄ‡ filmy akcji\n",
            "LubiÄ™ oglÄ…daÄ‡ filmy akcji\n",
            "Kawa na Å›niadanie piÄ‡\n",
            "PijÄ™ kawÄ™ na Å›niadanie\n",
            "Dlaczego ona Å›miaÄ‡ siÄ™ ciÄ…gle?\n",
            "Dlaczego ona siÄ™ teraz Å›mieje?\n",
            "Miasto nocÄ… byÄ‡ piÄ™kny\n",
            "Miasto jest piÄ™kne nocÄ…\n",
            "On nowy komputer kupiÄ‡\n",
            "On kupiÅ‚ nowy komputer\n",
            "KsiÄ…Å¼ka byÄ‡ na stole\n",
            "KsiÄ…Å¼ka leÅ¼y na stole\n",
            "Dlaczego padaÄ‡ dzisiaj tak duÅ¼o?\n",
            "Dlaczego dzisiaj pada tak duÅ¼o?\n",
            "My w niedzielÄ™ iÅ›Ä‡ do koÅ›ciÃ³Å‚\n",
            "Idziemy do koÅ›cioÅ‚a w niedzielÄ™\n",
            "SÅ‚oÅ„ce wschodziÄ‡ na wschodnie\n",
            "SÅ‚oÅ„ce wschodzi na wschodnie sÅ‚oÅ„ce\n",
            "Mama gotowaÄ‡ rosÃ³Å‚ jutro\n",
            "Mama jutro gotuje rosÃ³Å‚\n",
            "Ja rano biegaÄ‡ w parku\n",
            "Biegam rano w parku\n",
            "Kto rozumieÄ‡ ten problem?\n",
            "Kto rozumie ten problem?\n",
            "Ja w zeszÅ‚ym tygodniu odwiedziÄ‡ babciÄ™\n",
            "OdwiedziÅ‚em babciÄ™ w zeszÅ‚ym tygodniu\n",
            "DziÅ› mieÄ‡ test z matematyka\n",
            "DziÅ› test z matematyki\n",
            "Czasami padaÄ‡ Å›nieg w zimÄ™\n",
            "Czasami pada Å›nieg w zimie\n",
            "On wiedzieÄ‡ o tym spotkanie?\n",
            "On wie o tym spotkaniu?\n",
            "Kiedy wyjeÅ¼dÅ¼aÄ‡ na wakacje?\n",
            "Kiedy wyjeÅ¼dÅ¼asz na wakacje?\n",
            "Ja musieÄ‡ kupiÄ‡ mleko\n",
            "MuszÄ™ kupiÄ‡ mleko\n",
            "Samolot lÄ…dowaÄ‡ za dwie godziny\n",
            "Samolot lÄ…duje za dwie godziny\n",
            "LubiÄ‡ wspinaÄ‡ siÄ™ na gÃ³ry\n",
            "Lubi wspinaÄ‡ siÄ™ na gÃ³ry\n",
            "Dlaczego zwlekaÄ‡ z decyzja?\n",
            "Dlaczego zwlekasz z decyzjÄ…?\n",
            "On wczoraj oglÄ…daÄ‡ film\n",
            "On oglÄ…daÅ‚ film wczoraj\n",
            "Ja w kaÅ¼da niedziela biegaÄ‡\n",
            "Biegam w niedzielÄ™\n",
            "Nasze koty lubiÄ‡ spaÄ‡ w Å‚Ã³Å¼ko\n",
            "Nasze koty lubiÄ… spaÄ‡ w Å‚Ã³Å¼ku\n",
            "Gdzie on mieszkaÄ‡ teraz?\n",
            "Gdzie on teraz mieszka?\n",
            "Kot piÄ‡ mleko kaÅ¼dego rana\n",
            "Kot pije mleko kaÅ¼dego rana\n",
            "On moralny czÅ‚owiek\n",
            "On jest moralny\n",
            "Czy twÃ³j samochÃ³d mieÄ‡ benzyna?\n",
            "Czy masz benzynÄ™ w samochodzie?\n",
            "PiszÄ™ list do cioci\n",
            "PiszÄ™ list do cioci\n",
            "Czy ona mieÄ‡ nowÄ… pracÄ™?\n",
            "Czy ona ma nowÄ… pracÄ™?\n",
            "ÅšwiatÅ‚o sÅ‚oÅ„ca odbijaÄ‡ siÄ™ od woda\n",
            "ÅšwiatÅ‚o sÅ‚oÅ„ca odbija siÄ™ od wody\n",
            "Czy mÃ³gÅ‚byÅ› podaÄ‡ mi sÅ‚ownik?\n",
            "Czy mÃ³gÅ‚bym mi podaÄ‡ sÅ‚ownik?\n",
            "Dzieci lubiÄ‡ bawiÄ‡ siÄ™ na plac zabaw\n",
            "Dzieci lubiÄ… bawiÄ‡ siÄ™ na placu zabaw\n",
            "Droga byÄ‡ dÅ‚uga, ale piÄ™kna\n",
            "PodrÃ³Å¼ jest dÅ‚uga i piÄ™kna\n",
            "Kiedy zaczynaÄ‡ siÄ™ wakacje?\n",
            "Kiedy zaczynasz wakacje?\n",
            "KamieÅ„ w Sankt Petersburg byÄ‡ piÄ™kny\n",
            "On jest piÄ™kny w Sankt Petersburgu\n",
            "PijÄ™ ciepÅ‚a herbata wieczorem\n",
            "PijÄ™ ciepÅ‚Ä… herbatÄ™ wieczorem\n",
            "Czy lubisz zielona herbata?\n",
            "Czy lubisz zielonÄ… herbatÄ™?\n",
            "On czÄ™sto chodziÄ‡ na ryby\n",
            "On czÄ™sto chodzi na ryby\n",
            "Gdzie znajdowaÄ‡ siÄ™ najbliÅ¼sza stacja paliw?\n",
            "Gdzie znajduje siÄ™ najbliÅ¼sza stacja paliw?\n",
            "Latem ja lubiÄ‡ jeÅºdziÄ‡ na rower\n",
            "LubiÄ™ jeÅºdziÄ‡ na rowerze latem\n",
            "Czy mÃ³gÅ‚byÅ› pomÃ³c mi z zadaniem?\n",
            "Czy mÃ³gÅ‚byÅ› mi pomÃ³c?\n",
            "Piosenki odtwarzaÄ‡ na radio\n",
            "Åšpiewamy piosenki na radiu\n",
            "Ona byÄ‡ bardzo utalentowana piosenkarka\n",
            "Ona jest bardzo utalentowana jako piosenkarka\n",
            "ChciaÅ‚bym odwiedziÄ‡ Chiny pewnego dnia\n",
            "OdwiedziÅ‚em Chiny pewnego dnia\n",
            "Czy moÅ¼esz powiedzieÄ‡ mi sekret?\n",
            "Czy moÅ¼esz mi zdradziÄ‡ sekret?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2c7bb302e19d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_translation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1740\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 )\n\u001b[1;32m   1105\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1107\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mhidden_gelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0mhidden_linear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_gelu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QyKZwKt-ZJs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "244805af76a84bb38095849d01f2abed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d092a95057a408e991c54ad6fdab05e",
              "IPY_MODEL_24de4b1003f241188c45a47c74cfae04",
              "IPY_MODEL_84f0e725714d421da33201a7865df480"
            ],
            "layout": "IPY_MODEL_f01e7d463a944b9d9793c09c335d2cab"
          }
        },
        "2d092a95057a408e991c54ad6fdab05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a6c82dc96541698526e2170401efd8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d8d962dfb95248a2b44f0a900a5c5162",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "24de4b1003f241188c45a47c74cfae04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca7b30312468402cbab9e85d5abfa8f8",
            "max": 1100541913,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1e45700a03c4aa2a6747f4f74db0f80",
            "value": 1100541913
          }
        },
        "84f0e725714d421da33201a7865df480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d104962739f45a4b7c0177ab504ca62",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eadc84de6f764f938674d6b81355fbce",
            "value": "â€‡1.10G/1.10Gâ€‡[00:05&lt;00:00,â€‡24.3MB/s]"
          }
        },
        "f01e7d463a944b9d9793c09c335d2cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7a6c82dc96541698526e2170401efd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d962dfb95248a2b44f0a900a5c5162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca7b30312468402cbab9e85d5abfa8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e45700a03c4aa2a6747f4f74db0f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d104962739f45a4b7c0177ab504ca62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eadc84de6f764f938674d6b81355fbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}